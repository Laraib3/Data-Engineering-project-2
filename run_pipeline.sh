#!/bin/bash

# Exit on error
set -e
python3 -m venv venv
# Load environment variables from .env
set -a
source .env
set +a

echo "üöÄ Activating virtual environment..."
source venv/bin/activate

echo "üì¶ Updating Python dependencies..."
pip install --upgrade pip setuptools wheel --only-binary=:all:

echo "üì¶ Installing Python dependencies..."
pip install --only-binary=:all: -r setup_requirements.txt

echo "üîÑ Reinstalling dependencies to ensure compatibility..."
pip uninstall -y numpy pyarrow snowflake-connector-python || true
pip install --only-binary=:all: -r setup_requirements.txt

echo "üì¶ Installing SnowSQL CLI..."

# Download and install SnowSQL
# curl -O https://sfc-repo.snowflakecomputing.com/snowsql/bootstrap/1.2/linux_x86_64/snowsql-1.2.31-linux_x86_64.bash
# bash snowsql-1.2.31-linux_x86_64.bash

# Add SnowSQL to PATH
export PATH="$HOME/.snowsql/bin:$PATH"

# (Optional) Persist to shell config for future use
if ! grep -q 'snowsql/bin' "$HOME/.bashrc"; then
  echo 'export PATH="$HOME/.snowsql/bin:$PATH"' >> "$HOME/.bashrc"
fi

# Confirm installation
if command -v snowsql &> /dev/null; then
  echo "‚úÖ SnowSQL installed successfully!"
else
  echo "‚ùå SnowSQL installation failed."
  exit 1
fi



echo "üîÅ Cleaning up any old containers..."
export COMPOSE_HTTP_TIMEOUT=300

docker-compose -f kafka/docker-compose.yml down -v --remove-orphans || true

export COMPOSE_HTTP_TIMEOUT=300
echo "üêò Starting Zookeeper and Kafka using Docker..."
docker-compose -f kafka/docker-compose.yml up --build -d

# Wait until Kafka is ready
echo "‚è≥ Waiting for Kafka to be ready..."
MAX_RETRIES=60
RETRY_INTERVAL=10
RETRIES=0

while ! nc -z localhost 29092; do
  sleep $RETRY_INTERVAL
  RETRIES=$((RETRIES + 1))
  echo "üîÅ Waiting for Kafka... ($RETRIES/$MAX_RETRIES)"
  if [ "$RETRIES" -ge "$MAX_RETRIES" ]; then
    echo "‚ùå Kafka did not start in expected time. Exiting..."
    exit 1
  fi
done

echo "‚úÖ Kafka is up and running!"

# Additional wait to ensure Kafka is fully ready
echo "‚è≥ Additional wait to ensure Kafka is fully ready..."
sleep 30

echo "üîÑ Starting Kafka consumer in background..."
python3 kafka_consumer_to_snowflake.py &
CONSUMER_PID=$!
sleep 100

echo "üì° Running mock data generator..."
python3 generator/mock_generator.py &
GENERATOR_PID=$!

# Let them run for 3 minutes
sleep 180

# Kill the mock data generator if still running
if ps -p $GENERATOR_PID > /dev/null; then
  kill $GENERATOR_PID
  echo "‚úÖ Mock data generator stopped."
fi

# Kill the Kafka consumer if still running
if ps -p $CONSUMER_PID > /dev/null; then
  kill $CONSUMER_PID
  echo "‚úÖ Kafka consumer stopped."
fi

echo "‚ùÑÔ∏è Creating Snowflake database, schema, and table..."

echo "Using Snowflake credentials:"
echo "Account: $SNOWFLAKE_ACCOUNT"
echo "User: $SNOWFLAKE_USER"
echo "Password: $SNOWFLAKE_PASSWORD"

snowsql -c snowflake_conn -f init_snowflake.sql

echo "üê≥ Starting Airflow using Docker..."
# export COMPOSE_HTTP_TIMEOUT=300
# docker-compose -f kafka/docker-compose.yml up --build -d

# Wait a bit for Airflow webserver to be ready
echo "‚è≥ Waiting for Airflow webserver to be ready..."
sleep 100

# Unpause the DAG before triggering it
docker exec -i kafka-airflow-webserver-1 airflow dags unpause  transform_snowflake_data
docker exec -i kafka-airflow-webserver-1 airflow dags unpause  snowflake_to_bigquery

sleep 100

echo "üéØ Triggering Airflow DAG: transform_snowflake_data"
docker exec -i kafka-airflow-webserver-1 airflow dags trigger transform_snowflake_data
sleep 200

echo "üéØ Triggering Airflow DAG: snowflake_to_bigquery"
docker exec -i kafka-airflow-webserver-1 airflow dags trigger snowflake_to_bigquery


echo "‚úÖ Pipeline execution completed!"
